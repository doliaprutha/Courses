{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "#################################################################################\n",
    "# Step 1: Create a table in our database to hold the stock data\n",
    "#################################################################################\n",
    "\n",
    "# import some standard modules we can use to download URLs \n",
    "import urllib.request\n",
    "import zipfile, os\n",
    "import time \n",
    "import sqlite3\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "                 \n",
    "conn = sqlite3.connect('example.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create table \n",
    "c.execute('CREATE TABLE prices (SYMBOL text, SERIES text, OPEN real, HIGH real, LOW real, CLOSE real, LAST real, PREVCLOSE real, TOTTRDQTY real, TOTTRDVAL real, TIMESTAMP date, TOTALTRADES real, ISIN text, PRIMARY KEY (SYMBOL, SERIES, TIMESTAMP))')\n",
    "conn.commit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "#################################################################################\n",
    "# Step 2: Download a bunch of files and unzip them \n",
    "#################################################################################\n",
    "\n",
    "\n",
    "def download(localZipFilePath,urlOfFileName):\n",
    "    # We already wrote the code for this bit in the drill on files. Lets just copy that over \n",
    "    # This bit of boiler plate code below is needed because the \n",
    "    # website of the National Stock Exchange tries to block automated \n",
    "    # programs (like this one!) from downloading files. \n",
    "    # This line is not needed with all websites, but there are a reasonable \n",
    "    # number that will block automated downloads, in which case the additional line below\n",
    "    # will circumvent the block. \n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8',\n",
    "           'Connection': 'keep-alive'}\n",
    "\n",
    "    # here below is the code that actually downloads the page and stores to file\n",
    "\n",
    "    # Make the web request - just as a web browser like Chrome or Mozilla would\n",
    "    # Note that we pass in the boilerplate code we just typed above\n",
    "    webRequest = urllib.request.Request(urlOfFileName, headers=hdr)\n",
    "\n",
    "    # Doing stuff with files is quite prone to errors in the disk or in the network\n",
    "    # connection, so use a try:/except: pair as safety net\n",
    "    try:\n",
    "        # Make the web request \n",
    "        page = urllib.request.urlopen(webRequest)\n",
    "        # Save the contents of the web request in a variable called 'content'.\n",
    "        # These contents are literally the zip file from the URL (i.e. what you'd get \n",
    "        # if you downloaded the URL manually)\n",
    "        content = page.read()\n",
    "        # Save the contents to the zip file on disk locally\n",
    "        # 1. open the barrel (file). The 'w' signifies that we intend to write, i.e \n",
    "        # put stuff into the barrel (file)\n",
    "        output = open(localZipFilePath, \"wb\")\n",
    "        # 2. write contents to file, i.e. actually put stuff in the barrel\n",
    "        output.write(bytearray(content))\n",
    "        # 3. close the barrel (i.e. the file)\n",
    "        output.close()\n",
    "    # this bit below, the except: block is what will get executed if any of the lines above throw errors\n",
    "    except(urllib.request.HTTPError, e):\n",
    "        # print out exactly what error, if any, resulted\n",
    "        print(e.fp.read())\n",
    "        # Let the user know that the download did not work, and that file needs to be manually downloaded\n",
    "        print(\"Looks like the download did not go through. Please download manually \\nFROM:\" + urlOfFileName + \"\\nTO:\" + localZipFilePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unzip(localZipFilePath, localExtractFilePath):\n",
    "    # This bit had also been written earlier. Copying that as well\n",
    "    # check if the zip file above was downloaded fine, else no point trying to extract\n",
    "    # note how the os.path.exists gives us a single-line way to check if a given file exists\n",
    "    if os.path.exists(localZipFilePath):\n",
    "        # if we are in here (the body of the if-statement), that means the file\n",
    "        # does indeed exist\n",
    "        print(\"Cool! \" + localZipFilePath + \" exists..proceeding\") \n",
    "        # A zip file can contain any number of files - we don't know upfront how many\n",
    "        # so initialize an empty array in which to save the names of the files\n",
    "        listOfFiles = []\n",
    "        # Open the barrel (the zip file). The 'rb' is very significant\n",
    "        #   r: read i.e. we plan to take stuff out of the barrel, not put stuff in\n",
    "        #   b: binary i.e. the barrel contains stuff that needs processing.\n",
    "        # That further processing is exactly what the code below will do using the \n",
    "        # zipfile library.  \n",
    "        fh = open(localZipFilePath, 'rb')\n",
    "        # We've opened the file, now pass it to the library zipfile, which will give \n",
    "        # us a variable, here called 'zipFileHandler' which knows exactly what to do \n",
    "        # with this file.\n",
    "        zipFileHandler = zipfile.ZipFile(fh)\n",
    "        # zipFileHandler knows how to read the list of zipped up files in the zip. \n",
    "        # Iterate over them in a for-loop. 'name' is the iterator variable. \n",
    "        for name in zipFileHandler.namelist():\n",
    "            # Extract this particular file, named 'name' to the directory called 'localExtractFilePath'\n",
    "            zipFileHandler.extract(name, localExtractFilePath)\n",
    "            # Add this file to the list of files that we are maintaining\n",
    "            listOfFiles.append(localExtractFilePath + name)\n",
    "            print(\"Extracted \" + name + \" from the zip file, and saved to \" + (localExtractFilePath + name))\n",
    "        # note from the indentation that we are now outside the for loop!\n",
    "        # lets print the total number of files we extracted from our zip file\n",
    "        print(\"Extracted \" + str(len(listOfFiles)) + \" file in total\")\n",
    "        fh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def findDate(date):\n",
    "    day=datetime.datetime.strptime(date,'%d %b %Y').weekday()\n",
    "    return (calendar.day_name[day])\n",
    "\n",
    "\n",
    "def downloadAndUnzipForPeriod(listOfMonths, listOfyears):\n",
    "    for year in listOfYears:\n",
    "        # indentation changes - we are inside the first for loop ( for the years)\n",
    "        for month in listOfMonths:\n",
    "            # indentation changes yet again - we are inside the second for loop ( for each  month in a given year)\n",
    "            for dayOfMonth in range(31) : \n",
    "                date = dayOfMonth + 1 \n",
    "                # lists are indexed from 0 but the dates start from 1, so add 1 \n",
    "                ############################################################################\n",
    "                # OK the code that follows basically constructs a URL for the file \n",
    "                # as saved in the NSE website. How do we know how to construct this? \n",
    "                # Simply by manually downloading these files and examining the pattern for \n",
    "                # different dates/months/years. \n",
    "                # A typical URL looks like this : http://www.nseindia.com/content/historical/EQUITIES/2015/JUL/cm07JUL2015bhav.csv.zip\n",
    "                #############################################################################\n",
    "                # Convert number to string\n",
    "                dateStr = str(date)\n",
    "                # Note how single digit dates have a leading 0 \n",
    "                if date < 10:\n",
    "                    # indentation shows we are inside the if condition \n",
    "                    dateStr = \"0\"+dateStr\n",
    "                    # tack on a leading zero\n",
    "                # indentation changes - we are out of the if loop \n",
    "                print(dateStr, \"-\", month,\"-\", year)\n",
    "                newDate = dateStr + \" \" + month + \" \"+ year\n",
    "                dayOfWeek = findDate(newDate)\n",
    "                if dayOfWeek == \"Monday\" or dayOfWeek == \"Tuesday\" or dayOfWeek == \"Wednesday\" or dayOfWeek == \"Thursday\" or dayOfWeek == \"Friday\":\n",
    "                    # Construct the filename\n",
    "                    fileName = \"cm\" +str(dateStr) + str(month) + str(year) + \"bhav.csv.zip\"\n",
    "                    # Construct the entire URL\n",
    "                    urlOfFileName = \"http://archives.nseindia.com/content/historical/EQUITIES/\"+ year +\"/\"+ month + \"/\" + fileName\n",
    "                    # Construct the file on our local hard disk where we wish to save the downloaded file\n",
    "                    # The file path would look different on Windows machines\n",
    "                    localZipFilePath = \"C:\\Spring 2020\\Clinical Modelling\" + fileName\n",
    "                    # Make the call to the download function \n",
    "                    download(localZipFilePath, urlOfFileName)\n",
    "                    # MAke the call to the unzip function \n",
    "                    unzip(localZipFilePath,localExtractFilePath)\n",
    "                    # We want to make sure that we don't inadvertently overwhelm the NSE website\n",
    "                    # so take a pause of 10 seconds to make sure we are not overloading it \n",
    "                    time.sleep(10)\n",
    "                    # done with all 3 for loops , the years, months and days\n",
    "        print(\"OK, all done downloading and extracting\")\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm01JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm01JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm01JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "02 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm02JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm02JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm02JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "03 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm03JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm03JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm03JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "04 - JAN - 2014\n",
      "05 - JAN - 2014\n",
      "06 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm06JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm06JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm06JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "07 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm07JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm07JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm07JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "08 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm08JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm08JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm08JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "09 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm09JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm09JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm09JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "10 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm10JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm10JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm10JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "11 - JAN - 2014\n",
      "12 - JAN - 2014\n",
      "13 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm13JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm13JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm13JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "14 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm14JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm14JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm14JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "15 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm15JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm15JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm15JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "16 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm16JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm16JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm16JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "17 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm17JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm17JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm17JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "18 - JAN - 2014\n",
      "19 - JAN - 2014\n",
      "20 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm20JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm20JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm20JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "21 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm21JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm21JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm21JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "22 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm22JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm22JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm22JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "23 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm23JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm23JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm23JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "24 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm24JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm24JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm24JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "25 - JAN - 2014\n",
      "26 - JAN - 2014\n",
      "27 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm27JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm27JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm27JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "28 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm28JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm28JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm28JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "29 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm29JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm29JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm29JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "30 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm30JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm30JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm30JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "31 - JAN - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm31JAN2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm31JAN2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm31JAN2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "01 - FEB - 2014\n",
      "02 - FEB - 2014\n",
      "03 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm03FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm03FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm03FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "04 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm04FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm04FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm04FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "05 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm05FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm05FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm05FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "06 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm06FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm06FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm06FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "07 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm07FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm07FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm07FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "08 - FEB - 2014\n",
      "09 - FEB - 2014\n",
      "10 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm10FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm10FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm10FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "11 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm11FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm11FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm11FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "12 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm12FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm12FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm12FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "13 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm13FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm13FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm13FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "14 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm14FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm14FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm14FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "15 - FEB - 2014\n",
      "16 - FEB - 2014\n",
      "17 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm17FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm17FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm17FEB2014bhav.csv\n",
      "Extracted 1 file in total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm18FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm18FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm18FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "19 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm19FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm19FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm19FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "20 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm20FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm20FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm20FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "21 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm21FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm21FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm21FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "22 - FEB - 2014\n",
      "23 - FEB - 2014\n",
      "24 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm24FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm24FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm24FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "25 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm25FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm25FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm25FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "26 - FEB - 2014\n",
      "Cool! C:\\Spring 2020\\Clinical Modellingcm26FEB2014bhav.csv.zip exists..proceeding\n",
      "Extracted cm26FEB2014bhav.csv from the zip file, and saved to C:\\Spring 2020\\Clinical Modellingcm26FEB2014bhav.csv\n",
      "Extracted 1 file in total\n",
      "27 - FEB - 2014\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-727d216d5324>\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(localZipFilePath, urlOfFileName)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Make the web request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebRequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Save the contents of the web request in a variable called 'content'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1359\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1360\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1052\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-a27c005d705f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlistOfYears\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'2014'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdownloadAndUnzipForPeriod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistOfMonths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlistOfYears\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-9b4a5a2fa29c>\u001b[0m in \u001b[0;36mdownloadAndUnzipForPeriod\u001b[1;34m(listOfMonths, listOfyears)\u001b[0m\n\u001b[0;32m     39\u001b[0m                     \u001b[0mlocalZipFilePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\Spring 2020\\Clinical Modelling\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfileName\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[1;31m# Make the call to the download function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                     \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalZipFilePath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murlOfFileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                     \u001b[1;31m# MAke the call to the unzip function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0munzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalZipFilePath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlocalExtractFilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-727d216d5324>\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(localZipFilePath, urlOfFileName)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# this bit below, the except: block is what will get executed if any of the lines above throw errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;31m# print out exactly what error, if any, resulted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "#initialize a variable with a local directory in which to extract the \n",
    "# zip file above\n",
    "localExtractFilePath = \"C:\\Spring 2020\\Clinical Modelling\"\n",
    "\n",
    "\n",
    "\n",
    "listOfMonths = ['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']\n",
    "listOfYears = ['2014']\n",
    "\n",
    "downloadAndUnzipForPeriod(listOfMonths,listOfYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "#####################################################################\n",
    "# Step 3: parse each file, and insert each row of each file into the database\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "def insertRows(fileName,conn):\n",
    "    # conn is a connection to the database, \n",
    "    # given a connection we need a session in which to do stuff\n",
    "    c = conn.cursor()\n",
    "    lineNum = 0 \n",
    "    with open(fileName, 'r') as csvfile:\n",
    "        # the file is opened now let's get a csv handler. The handler needs to be told how strings in quotes \n",
    "        # will appear - we tell it that quotes will be marked by double quotes \n",
    "        lineReader = csv.reader(csvfile, delimiter = ',', quotechar = \"\\\"\")\n",
    "        # Ok! the CSV handler called 'lineReader' knows how to read a file 1 line at a time\n",
    "        # Iterate using a for loop and the iterator variable 'row'\n",
    "        \n",
    "        for row in lineReader:\n",
    "            # what line are we on? Increase the counter by 1\n",
    "            lineNum = lineNum + 1\n",
    "            # if this was the first line - which contains a header - skip and \n",
    "            # go to the next via the 'continue' statement\n",
    "            if lineNum ==1:\n",
    "                print(\"Header row, skipping\")\n",
    "                continue\n",
    "            # Insert a row of data \n",
    "            date_object = datetime.strptime(row[10], '%d-%b-%Y')\n",
    "            #############################################################################\n",
    "            # We just wrote to the database, so we must commit our writes \n",
    "            #############################################################################\n",
    "            # We will insert data into the database 1 row at a time. This data must correspond\n",
    "            # in the number and type to the column headers of the table. The columns in a table are \n",
    "            # collectively called the schema \n",
    "            oneTuple = [row[0], row[1], float(row[2]),float(row[3]),float(row[4]),float(row[5]),float(row[6]),float(row[7]),float(row[8]),float(row[9]),date_object,float(row[11]),row[12]]                \n",
    "            # This statement will actually insert a single row into the table called prices\n",
    "            c.execute(\"INSERT INTO prices VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)\",oneTuple)\n",
    "        # As the changed indentation tells us, we are now out of the for - loop, as well as out of the 'with' block. \n",
    "        # The magic bit of the 'with...' statement is that the file (barrel) we had opened is closed without our doing \n",
    "        # anything explicit\n",
    "        ##################################################################################\n",
    "        # We just wrote to the database, so we must commit our writes \n",
    "        ###################################################################################\n",
    "        conn.commit()\n",
    "        print(\"Done iterating over file contents - the file has been closed now!\")\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n",
      "Header row, skipping\n",
      "Done iterating over file contents - the file has been closed now!\n"
     ]
    }
   ],
   "source": [
    "# Insert into table \n",
    "import os, csv, datetime \n",
    "from datetime import datetime \n",
    "\n",
    "localExtractFilePath = \"C:\\Spring 2020\\Clinical Modelling\"\n",
    "# USe a python library to get a list of all files in a particular directory \n",
    "for file in os.listdir(localExtractFilePath):\n",
    "    # as the indentation tells we are in body of the loop \n",
    "    # 'file' is the name of the loop variable \n",
    "    if file.endswith(\".csv\"):\n",
    "        # Yet another indentation change - we are now inside the if condition\n",
    "        # IF the filename ends with '.csv' its a file we care about - make a function \n",
    "        # call to the function above to insert into the database \n",
    "        insertRows(localExtractFilePath+\"/\"+file,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ICICIBANK', 1097.7, 958.05, '2014-02-26 00:00:00', '2014-01-01 00:00:00', 41)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[10]:\n",
    "\n",
    "######################################################################\n",
    "# Step 4: Run a test query against the database to make sure it is set up OK \n",
    "######################################################################\n",
    "\n",
    "t1 = 'ICICIBANK'\n",
    "series = 'EQ'\n",
    "c = conn.cursor()\n",
    "cursor = c.execute ('SELECT symbol, max(close), min(close), max(timestamp), min(timestamp), count(timestamp) FROM prices WHERE symbol = ? and series = ? GROUP BY symbol ORDER BY timestamp', (t1,series))\n",
    "for row in cursor: \n",
    "    print(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[11]:\n",
    "\n",
    "##########################################################################\n",
    "# Step 5: Run a query to get all data for a given stock, and create an excel summary\n",
    "##########################################################################\n",
    "\n",
    "import xlsxwriter\n",
    "# we need xlsxwriter in order to  create excel files\n",
    "\n",
    "\n",
    "def createExcelWithDailyPriceMoves(ticker,conn):\n",
    "    # get a cursor from the connection\n",
    "    # we will use this cursor to execute SQL commands \n",
    "    c = conn.cursor()\n",
    "    # Now execute a query (i.e. read from the database) to get all information for this particular ticker \n",
    "    cursor = c.execute('SELECT symbol, timestamp, close FROM prices where symbol = ? and series = ? ORDER BY timestamp',(ticker,series))\n",
    "    # pay close attention to the way '?' is used - twice - once each as placeholder for the symbol and for the series \n",
    "    # This is a standard way of passing inputs to customize queries. Also note the syntax used to pass in the 2 inputs \n",
    "    \n",
    "    \n",
    "    # import the xlsxwriter which does all the magic \n",
    "    # Initialize a variable with the name of the excel file we will create - \n",
    "    # this will have the same name as the ticker that we care about \n",
    "    excelFileName = \"C:\\Spring 2020\\Clinical Modelling\\Outputs\"+ticker+\".xlsx\"\n",
    "    # create a workbook. This in a different way is opening a file \n",
    "    workbook = xlsxwriter.Workbook(excelFileName)\n",
    "    # Create an empty worksheet in this workbook, named 'summary' \n",
    "    worksheet = workbook.add_worksheet(\"Summary\")\n",
    "    # The way we write stuff into this excel workbook is passing \n",
    "    # the cell address to start write stuff eg \"A1\"\n",
    "    # a list of values that will be written , 1 per cell starting from that address \n",
    "    worksheet.write_row(\"A1\",[\"Top Traded Stocks\"])\n",
    "    worksheet.write_row(\"A2\",['Stock','Date','Closing'])\n",
    "    lineNum = 3 \n",
    "    # Everything in life is a list - notice how the results of the query are a list \n",
    "    # and we can iterate over this list of results using a for loop \n",
    "    for row in cursor: \n",
    "        worksheet.write_row(\"A\"+str(lineNum), list(row))\n",
    "        print(\"A\"+str(lineNum),list(row))\n",
    "        lineNum = lineNum + 1 \n",
    "    # Indentation changes - we are done with the for loop that writes the raw data \n",
    "    # Ok - all of the code after this is devoted to creating a line chart in excel \n",
    "    chart1 = workbook.add_chart({'type':'line'})\n",
    "    # Configure the first series \n",
    "    chart1.add_series({\n",
    "            'categories': '=Summary!$B$3:$B$' + str(lineNum),\n",
    "            'values': '=Summary!$C$3:$C$'+str(lineNum)\n",
    "            # check out this boiler plate code that tells xlsxwriter where to find the data for his chart \n",
    "            # We know that we started writing the data in cell B3, and that the last row we filled in \n",
    "            # is still stored in the 'lineNum' variable\n",
    "        })\n",
    "    # Add a chart title and some axis labels\n",
    "    chart1.set_title({'name': ticker})\n",
    "    chart1.set_x_axis({'name':'Date'})\n",
    "    chart1.set_y_axis({'name': 'Closing Price'})\n",
    "    \n",
    "    # Insert the chart into the worksheet (with an offset)\n",
    "    worksheet.insert_chart('F2',chart1,{'x_offset': 25, 'y_offset': 10})\n",
    "    workbook.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3 ['RELIANCE', '2014-01-01 00:00:00', 888.8]\n",
      "A4 ['RELIANCE', '2014-01-02 00:00:00', 875.0]\n",
      "A5 ['RELIANCE', '2014-01-03 00:00:00', 864.25]\n",
      "A6 ['RELIANCE', '2014-01-06 00:00:00', 854.95]\n",
      "A7 ['RELIANCE', '2014-01-07 00:00:00', 842.1]\n",
      "A8 ['RELIANCE', '2014-01-08 00:00:00', 849.05]\n",
      "A9 ['RELIANCE', '2014-01-09 00:00:00', 850.7]\n",
      "A10 ['RELIANCE', '2014-01-10 00:00:00', 858.15]\n",
      "A11 ['RELIANCE', '2014-01-13 00:00:00', 880.4]\n",
      "A12 ['RELIANCE', '2014-01-14 00:00:00', 881.5]\n",
      "A13 ['RELIANCE', '2014-01-15 00:00:00', 885.45]\n",
      "A14 ['RELIANCE', '2014-01-16 00:00:00', 886.15]\n",
      "A15 ['RELIANCE', '2014-01-17 00:00:00', 884.75]\n",
      "A16 ['RELIANCE', '2014-01-20 00:00:00', 869.75]\n",
      "A17 ['RELIANCE', '2014-01-21 00:00:00', 863.05]\n",
      "A18 ['RELIANCE', '2014-01-22 00:00:00', 872.45]\n",
      "A19 ['RELIANCE', '2014-01-23 00:00:00', 865.8]\n",
      "A20 ['RELIANCE', '2014-01-24 00:00:00', 867.65]\n",
      "A21 ['RELIANCE', '2014-01-27 00:00:00', 843.15]\n",
      "A22 ['RELIANCE', '2014-01-28 00:00:00', 844.85]\n",
      "A23 ['RELIANCE', '2014-01-29 00:00:00', 836.6]\n",
      "A24 ['RELIANCE', '2014-01-30 00:00:00', 825.0]\n",
      "A25 ['RELIANCE', '2014-01-31 00:00:00', 831.15]\n",
      "A26 ['RELIANCE', '2014-02-03 00:00:00', 820.9]\n",
      "A27 ['RELIANCE', '2014-02-04 00:00:00', 821.55]\n",
      "A28 ['RELIANCE', '2014-02-05 00:00:00', 817.25]\n",
      "A29 ['RELIANCE', '2014-02-06 00:00:00', 815.85]\n",
      "A30 ['RELIANCE', '2014-02-07 00:00:00', 814.45]\n",
      "A31 ['RELIANCE', '2014-02-10 00:00:00', 821.95]\n",
      "A32 ['RELIANCE', '2014-02-11 00:00:00', 805.25]\n",
      "A33 ['RELIANCE', '2014-02-12 00:00:00', 817.9]\n",
      "A34 ['RELIANCE', '2014-02-13 00:00:00', 807.4]\n",
      "A35 ['RELIANCE', '2014-02-14 00:00:00', 822.05]\n",
      "A36 ['RELIANCE', '2014-02-17 00:00:00', 812.3]\n",
      "A37 ['RELIANCE', '2014-02-18 00:00:00', 813.15]\n",
      "A38 ['RELIANCE', '2014-02-19 00:00:00', 812.25]\n",
      "A39 ['RELIANCE', '2014-02-20 00:00:00', 805.45]\n",
      "A40 ['RELIANCE', '2014-02-21 00:00:00', 811.5]\n",
      "A41 ['RELIANCE', '2014-02-24 00:00:00', 812.35]\n",
      "A42 ['RELIANCE', '2014-02-25 00:00:00', 810.55]\n",
      "A43 ['RELIANCE', '2014-02-26 00:00:00', 810.7]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Create a connection \n",
    "conn=sqlite3.connect('example.db')\n",
    "# Call the function above to create an excel file for the ticker \n",
    "# RELIANCE which is one of Indias most actively traded stocks \n",
    "createExcelWithDailyPriceMoves('RELIANCE',conn)\n",
    "# Close the connection. We only queried (read) from the database \n",
    "# so there is no need to commit \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[12]:\n",
    "\n",
    "################################################################\n",
    "# Step 6: We will also see how to drop a table to clear up \n",
    "##################################################################\n",
    "\n",
    "# Drop table \n",
    "# Step 1: open up a connection \n",
    "conn=sqlite3.connect('example.db')\n",
    "# Step 2: get a cursor \n",
    "c = conn.cursor()\n",
    "# Step 3 : Drop the table so we leave the database in the same state in which we started with \n",
    "c.execute('DROP TABLE prices')\n",
    "# Step 4 : OK - we wrote to the database, so we must commit our changes\n",
    "conn.commit()\n",
    "# Step 5 : Close the connection \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
